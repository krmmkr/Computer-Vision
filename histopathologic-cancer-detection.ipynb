{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport random\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report \nfrom sklearn.metrics import roc_curve, auc\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd253f00aed371992f8f915530d3e435adb6a69e"},"cell_type":"code","source":"label_csv = pd.read_csv(\"../input/train_labels.csv\")\nlabel_csv_train, label_csv_test = train_test_split(label_csv, test_size=0.3, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def import_data(labl):\n    x_sample=[]\n    y=[]\n    for img in labl['id']:\n        #if (labl['id'].where(labl['id'] == img)).empty == False:\n            path = os.path.join(\"../input/train/\", img +'.tif')\n            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n            img = cv2.resize(img, (50,50))\n            x_sample.append(np.array(img))\n            \n    y = np.array(labl['label'])\n    return x_sample, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41ff35687f36a0ae5f5567817b1e750f56a3f4d0"},"cell_type":"code","source":"def error_rate(p, t):\n    return np.mean(p != t)\ndef standardize(x):\n    return (x/255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2f1e33ade960486934cde1d300b1cdad354400b"},"cell_type":"code","source":"def convolution(x, w, b, pad):\n    conv_out = tf.nn.conv2d(x, w, strides=[1,1,1,1], padding=pad)\n    conv_out = tf.nn.bias_add(conv_out, b)\n    return conv_out\ndef pooling(conv_out):\n    pool_out = tf.nn.max_pool(conv_out, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n    return tf.nn.relu(pool_out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"115f0d2c0c31b70fbefa0713898616b9fb86bb37"},"cell_type":"code","source":"def init_filter(shape, poolsz):\n    # w = np.random.randn(*shape) * np.sqrt(2) / np.sqrt(np.prod(shape[:-1]) + shape[-1]*np.prod(shape[:-2]) / np.prod(poolsz))\n    w = np.random.randn(*shape) * np.sqrt(2.0 / np.prod(shape[:-1]))\n    #w = np.random.randn(*shape)\n    return w.astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f48294af9045d1d8fc3c1196e7991cc539c2e72"},"cell_type":"code","source":"#hyperparameters\nmax_iter = 50\nlr=0.01\nK=1\npoolsz = (2,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"221986666362c9cdad6c08f8f858e17ca9f83022"},"cell_type":"code","source":"#bias and weights\n#Convolution\nw1_shape = (3,3,1,20)\nw1_init = init_filter(w1_shape, poolsz)\nb1_init = np.zeros(w1_shape[-1], dtype = np.float32)\n\nw2_shape = (3,3,20,50)\nw2_init = init_filter(w2_shape, poolsz)\nb2_init = np.zeros(w2_shape[-1], dtype = np.float32)\n\nw3_shape = (3,3,50,100)\nw3_init = init_filter(w3_shape, poolsz)\nb3_init = np.zeros(w3_shape[-1], dtype = np.float32)\n\nw4_shape = (7,7,100,K)\nw4_init = init_filter(w4_shape, poolsz)\nb4_init = np.zeros(w4_shape[-1], dtype = np.float32)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6cc0b7502b20350e334657cb4960d219560d0e1"},"cell_type":"code","source":"#tf variables and place holders\nx = tf.placeholder(tf.float32, shape=(None,50,50,1), name='x')\nt = tf.placeholder(tf.float32, shape=(None, K), name = 't')\nw1 = tf.Variable(w1_init.astype(np.float32))\nb1 = tf.Variable(b1_init.astype(np.float32))\nw2 = tf.Variable(w2_init.astype(np.float32))\nb2 = tf.Variable(b2_init.astype(np.float32))\nw3 = tf.Variable(w3_init.astype(np.float32))\nb3 = tf.Variable(b3_init.astype(np.float32))\nw4 = tf.Variable(w4_init.astype(np.float32))\nb4 = tf.Variable(b4_init.astype(np.float32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11943c83c086339d048bd1ed71ca9c84910769d2"},"cell_type":"code","source":"#define model\nc_out1 = convolution(x, w1, b1, \"SAME\")\nz1 = pooling(c_out1)\n\nc_out2 = convolution(z1, w2, b2, \"SAME\")\nz2 = pooling(c_out2)\n\nc_out3 = convolution(z2, w3, b3, \"SAME\")\nz3 = pooling(c_out3)\n\nc_out4 = convolution(z3, w4, b4, \"VALID\")\n\ncalcY = tf.reshape(c_out4,[-1,K])\n#cost\ncost = tf.reduce_sum(\n        tf.nn.sigmoid_cross_entropy_with_logits(\n            logits=calcY,\n            labels=t\n        )\n    )\n#optimizer - adam\ntrain_op = tf.train.AdamOptimizer(0.001).minimize(cost)\n#optimizer - RMS Prop\n#train_op = tf.train.RMSPropOptimizer(0.01, decay=0.99, momentum=0.9).minimize(cost)\n#softmax - predict probability for each class\npredictor_y_prob = tf.nn.sigmoid(calcY)\n#y predicted\npredictor_y = tf.round(predictor_y_prob)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d88f36f99e5033df2479fccb63e20241229829a"},"cell_type":"code","source":"def process(size):\n    df0 = label_csv_train[label_csv_train.label == 0].sample(size, random_state = random.randint(1,99))\n    df1 = label_csv_train[label_csv_train.label == 1].sample(size, random_state = random.randint(1,99))\n    label_csv = pd.concat([df0, df1], ignore_index=True).reset_index()\n    label_csv = label_csv[[\"id\", \"label\"]]\n    x, y = import_data(label_csv)\n    x = np.array(x)\n    x = x.reshape(-1,50,50,1)\n    x = standardize(x)\n    y = y.reshape(-1, 1)\n    return x,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4591ab89197ded8af67246f5103244cac2bcd99f","scrolled":true},"cell_type":"code","source":"#arrays\ntrain_costs = []\n\n#initializing session\ninit = tf.global_variables_initializer()\nwith tf.Session() as session:\n    session.run(init)\n    \n    for i in range(50):\n        print(\"i\",i)\n        for j in range(50):\n            print(\"j\",j)\n            x_sample, y_sample = process(5000)\n            session.run(train_op, feed_dict={x:x_sample, t: y_sample})\n            #train\n            train_cost = session.run(cost, feed_dict={x: x_sample, t: y_sample})\n            train_costs.append(train_cost)\n            #z = session.run(z2r, feed_dict={x:x_train})\n            \n    x_sample, y_sample = process(5000)\n    y_train_predicted = session.run(predictor_y, feed_dict={x: x_sample})\n    y_train_predicted_prob = session.run(predictor_y_prob, feed_dict={x: x_sample})\n    \n    y_test_predicted_prob = session.run(predictor_y_prob, feed_dict={x: x_sample})\n    y_test_predicted = session.run(predictor_y, feed_dict={x: x_sample})\n    #wtest = session.run(calcY, feed_dict={x: x_test})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ab6ef44c487a7da6068a1d3de8cd7e45d0d455f"},"cell_type":"code","source":"err = error_rate(y_sample, y_test_predicted)\nerr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc7a1cb6a8161c44dd3ff6b4de536cfcc6b62f1d"},"cell_type":"code","source":"FPR, TPR, _ = roc_curve(y_sample, y_test_predicted_prob)\nAUC = auc(FPR, TPR)\nplt.figure()\nplt.plot(FPR, TPR, label='ROC curve (area = %0.2f)' % AUC)\nplt.plot([0, 1], [0, 1], 'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.02])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}